{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\Documents\\\\EndToEndMLProjects\\\\End-To-End-Machine-Learning-Project-with-MlFlow\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\Documents\\\\EndToEndMLProjects\\\\End-To-End-Machine-Learning-Project-with-MlFlow'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Update config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Update the entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataManipulationConfig:\n",
    "    root_dir: Path\n",
    "    cleaned_data_dir: str\n",
    "    manipulated_data_dir: str\n",
    "    STATUS_FILE: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Update the configuration manager in src config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlproject.constants import *\n",
    "from mlproject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    Manages the configuration and setup for the project.\n",
    "\n",
    "    This class is responsible for reading configuration files, creating required directories, \n",
    "    and providing specific configuration objects needed for various components of the project.\n",
    "\n",
    "    Attributes:\n",
    "        config (dict): Parsed content of the main configuration file.\n",
    "        params (dict): Parsed content of the parameters file.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the ConfigurationManager.\n",
    "\n",
    "        Reads YAML configuration files for main configuration, parameters, and schema. \n",
    "        Also ensures that the root artifacts directory specified in the configuration is created.\n",
    "\n",
    "        Args:\n",
    "            config_filepath (str): Path to the main configuration YAML file. Default is `CONFIG_FILE_PATH`.\n",
    "            params_filepath (str): Path to the parameters YAML file. Default is `PARAMS_FILE_PATH`.           \n",
    "        \"\"\"\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_data_manipulation_config(self) -> DataManipulationConfig:\n",
    "        \"\"\"\n",
    "        Creates and returns a `DataManipulationConfig` object for manipulating data.\n",
    "\n",
    "        This method retrieves the configuration details specific to manipulating data values from \n",
    "        the main configuration file. It also ensures that the directories required for this step \n",
    "        are created.\n",
    "\n",
    "        Returns:\n",
    "            DataManipulationConfig: An instance of `DataManipulationConfig` containing paths \n",
    "            and other configuration details for manipulating data.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If an error occurs while retrieving the manipulating data configuration.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            config = self.config.data_manipulation\n",
    "            create_directories([config.root_dir])\n",
    "            \n",
    "            data_manipulation_config = DataManipulationConfig(\n",
    "                root_dir=config.root_dir,\n",
    "                cleaned_data_dir=config.cleaned_data_dir,\n",
    "                manipulated_data_dir=config.manipulated_data_dir,\n",
    "                STATUS_FILE=config.STATUS_FILE\n",
    "            )\n",
    "            return data_manipulation_config\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Update the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlproject import logger\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManipulateData:\n",
    "    \"\"\"\n",
    "    Handles data manipulation tasks for a dataset.\n",
    "\n",
    "    This class is responsible for correcting data types and modifying values in a dataset \n",
    "    based on specific rules. It reads the data from configured directories, applies the \n",
    "    changes, saves the modified data, and logs the status of operations.\n",
    "\n",
    "    Attributes:\n",
    "        config (DataManipulationConfig): Configuration object containing file paths and \n",
    "                                         directories required for data manipulation.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, config: DataManipulationConfig) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the ManipulateData object.\n",
    "\n",
    "        Args:\n",
    "            config (DataManipulationConfig): Configuration object containing file paths and \n",
    "                                             directories required for data manipulation.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        \n",
    "    def correct_dtype(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Corrects the data types of specific columns in the dataset.\n",
    "\n",
    "        - Converts the `term` column to an integer type.\n",
    "        - Converts the `Status` column to an object type.\n",
    "        - Saves the updated dataset to the configured directory.\n",
    "        - Logs the success status to the status file.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The DataFrame with corrected data types.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If an error occurs during the process.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(self.config.cleaned_data_dir)\n",
    "            \n",
    "            df['term'] = df['term'].astype('int')\n",
    "            df['Status'] = df['Status'].astype('object')\n",
    "            \n",
    "            # Save the corrected DataFrame\n",
    "            corrected_df_file_path = self.config.manipulated_data_dir  # File path for saving\n",
    "            create_directories([os.path.dirname(corrected_df_file_path)])  # creates this directory \"artifacts/handle_missing_values\" if it doesn't already exist.\n",
    "            df.to_csv(corrected_df_file_path, index=False)\n",
    "            \n",
    "            # Log status\n",
    "            with open(self.config.STATUS_FILE, \"a\") as status_file:\n",
    "                status_file.write(\"Corrected dtypes and data saved successfully.\\n\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def change_values(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Replaces specific values in the dataset based on predefined rules.\n",
    "\n",
    "        - Fixes typos in the `Security_Type` column.\n",
    "        - Replaces codes in the `occupancy_type` column with descriptive labels.\n",
    "        - Saves the updated dataset to the configured directory.\n",
    "        - Logs the success status to the status file.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The DataFrame with updated values.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If an error occurs during the process.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(self.config.manipulated_data_dir)\n",
    "            \n",
    "            df['Security_Type'] = df['Security_Type'].replace({'Indriect':'Indirect'}) \n",
    "            df['occupancy_type'] = df['occupancy_type'].replace({'pr':'Primary Residential', 'sr':'Secondary Residdential', 'ir':'Investment Residential'}) \n",
    "            \n",
    "            # Save the corrected DataFrame\n",
    "            corrected_df_file_path = self.config.manipulated_data_dir  # File path for saving\n",
    "            create_directories([os.path.dirname(corrected_df_file_path)])  # creates this directory \"artifacts/handle_missing_values\" if it doesn't already exist.\n",
    "            df.to_csv(corrected_df_file_path, index=False)\n",
    "            \n",
    "            # Log status\n",
    "            with open(self.config.STATUS_FILE, \"a\") as status_file:\n",
    "                status_file.write(\"Corrected values and data saved successfully.\\n\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Update pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-20 12:01:47,943: 35 mlprojectLogger: INFO: common: .yaml file: config\\config.yaml loaded successfully.]\n",
      "[2024-11-20 12:01:47,945: 35 mlprojectLogger: INFO: common: .yaml file: params.yaml loaded successfully.]\n",
      "[2024-11-20 12:01:47,947: 54 mlprojectLogger: INFO: common: Created directory at artifacts]\n",
      "[2024-11-20 12:01:47,949: 54 mlprojectLogger: INFO: common: Created directory at artifacts/data_manipulation]\n",
      "[2024-11-20 12:01:48,875: 54 mlprojectLogger: INFO: common: Created directory at artifacts/data_manipulation]\n",
      "[2024-11-20 12:01:52,663: 54 mlprojectLogger: INFO: common: Created directory at artifacts/data_manipulation]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_manipulation_config = config.get_data_manipulation_config()\n",
    "    \n",
    "    manipulator = ManipulateData(data_manipulation_config)\n",
    "    manipulator.correct_dtype()\n",
    "    manipulator.change_values()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143942 entries, 0 to 143941\n",
      "Data columns (total 34 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   ID                         143942 non-null  int64  \n",
      " 1   year                       143942 non-null  int64  \n",
      " 2   loan_limit                 143942 non-null  object \n",
      " 3   Gender                     143942 non-null  object \n",
      " 4   approv_in_adv              143942 non-null  object \n",
      " 5   loan_type                  143942 non-null  object \n",
      " 6   loan_purpose               143942 non-null  object \n",
      " 7   Credit_Worthiness          143942 non-null  object \n",
      " 8   open_credit                143942 non-null  object \n",
      " 9   business_or_commercial     143942 non-null  object \n",
      " 10  loan_amount                143942 non-null  int64  \n",
      " 11  rate_of_interest           143942 non-null  float64\n",
      " 12  Interest_rate_spread       143942 non-null  float64\n",
      " 13  Upfront_charges            143942 non-null  float64\n",
      " 14  term                       143942 non-null  int64  \n",
      " 15  Neg_ammortization          143942 non-null  object \n",
      " 16  interest_only              143942 non-null  object \n",
      " 17  lump_sum_payment           143942 non-null  object \n",
      " 18  property_value             143942 non-null  float64\n",
      " 19  construction_type          143942 non-null  object \n",
      " 20  occupancy_type             143942 non-null  object \n",
      " 21  Secured_by                 143942 non-null  object \n",
      " 22  total_units                143942 non-null  object \n",
      " 23  income                     143942 non-null  float64\n",
      " 24  credit_type                143942 non-null  object \n",
      " 25  Credit_Score               143942 non-null  int64  \n",
      " 26  co-applicant_credit_type   143942 non-null  object \n",
      " 27  age                        143942 non-null  object \n",
      " 28  submission_of_application  143942 non-null  object \n",
      " 29  LTV                        143942 non-null  float64\n",
      " 30  Region                     143942 non-null  object \n",
      " 31  Security_Type              143942 non-null  object \n",
      " 32  Status                     143942 non-null  int64  \n",
      " 33  dtir1                      143942 non-null  float64\n",
      "dtypes: float64(7), int64(6), object(21)\n",
      "memory usage: 37.3+ MB\n"
     ]
    }
   ],
   "source": [
    "a = pd.read_csv('artifacts/data_manipulation/Manipulated_Loan_Default.csv')\n",
    "a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['direct', 'Indirect'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['Security_Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Primary Residential', 'Secondary Residdential',\n",
       "       'Investment Residential'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['occupancy_type'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
